{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'> CSC4120 Programming Assignment 3  </h1>\n",
    "\n",
    "## Submission Requirements\n",
    "\n",
    "   The submission <font color = #FF0000>deadline is March 17 (Sun.), 2024, 11:59 pm</font>. Solutions submitted after the deadline will be graded as 0 points. Please submit a **ipynb** file using given template and clearly state your group members' student IDs. Otherwise, your points will be deducted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Studen IDs\n",
    "\n",
    "120090244\n",
    "\n",
    "122090031\n",
    "\n",
    "121090271"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Remote Error Correction\n",
    "\n",
    "Prof. Costas was isolated in Xi'an. He was planning to work on the homework during the isolation. Unfortunately, his computer broke and corrupted the latest copy of the homework file. A few lines of the file were affected. Prof. Costas could just ask Mingjie, who was in Shenzhen, to send him the latest copy of the file. But the hotel he stayed has very slow and pricey Internet access.\n",
    "\n",
    "Help Prof. Costas recover the file and prepare homework on time! Design an interactive protocol for detecting and correcting corrupted lines that uses **little communication**.\n",
    "\n",
    "In this question, you have to answer two short-answer questions and implement the following three functions in file_compare.ipynb.\n",
    "(Feel free to add additional methods)\n",
    "\n",
    "* def hash_function(s)\n",
    "* def compute_node_value(table, i, j)\n",
    "* def binary_check_hash(left, right)\n",
    "\n",
    "First, Prof. Costas and Mingjie need a good hash function that can compute a hash value for any contiguous subset of lines of a file.\n",
    "\n",
    "1. Implement a **division hash** in the function `hash_function`.\n",
    "\n",
    "You can use bulit-in function `hash()` (or any other function) to calculate the hash code of a string, but you should make **your** `hash_function` a division hash. \n",
    "\n",
    "2. Implement the function `compute_node_value`.\n",
    "\n",
    "It computes all useful hash values for binary comparison (to be explained later), and store them in corresponding table (`HashCorruptedFile[][]` and `HashOriginalFile[][]`). It only calculates `HashCorruptedFile[0, n]`, `HashCorruptedFile[0, n/2]`, `HashCorruptedFile[0, n/4]`, `HashCorruptedFile[n/2, n]`, `HashCorruptedFile[n/4, n/2]` ... etc.\n",
    "\n",
    "Hints:\n",
    "- `wordsCorrupted[i]` := data of line i in the corrupted file\n",
    "- `HashCorruptedFile[i][i]` := Hash value of \"line i in the corrupted File\"\n",
    "- `HashCorruptedFile[i][j]` := Hash value of \"lines i to j in the corrupted File\"\n",
    "\n",
    "For example, if the corrupted file (4 lines) is as follows:\n",
    "\n",
    "```raw\n",
    "    aaaa\\n\n",
    "    bbbb\\n\n",
    "    cccc\\n\n",
    "    dddd\n",
    "```\n",
    "\n",
    "then,\n",
    "- `wordsCorrupted[0]` = \"aaaa\"\n",
    "- `HashCorruptedFile[0][0]` = hash function(\"aaaa\")\n",
    "- `HashCorruptedFile[1][1]` = hash function(\"bbbb\")\n",
    "- `HashCorruptedFile[0][2]` = hash function(temp). temp is something related to \"aaaa\",\n",
    "\"bbbb\" and \"cccc\", or related to their hash value. It depends on your own design.\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Prof. Costas and Mingjie have your hash function. They want to find the corrupted lines. Mingjie came up with a naive algorithm to compare both files line by line (and he wrote the codes in `naive_check_hash`). They could send and compare the hash value of each line. But Prof. Costas is unsatisfied with the communication cost $ \\Theta(n) $. Help them design an efficient algorithm! \n",
    "\n",
    "3. Suppose the two copies of the file differ in some number of consecutive lines.\n",
    "Let $ n $ be the total number of lines in the file. How can Prof. Costas and Mingjie use\n",
    "binary search to find the start and end of the corruption by exchanging only $ O(\\log n) $ hash\n",
    "values? Describe your idea below.\n",
    "\n",
    "\\###\n",
    "\n",
    "Pseudo code is below:\n",
    "\n",
    "\n",
    "        \n",
    "           \n",
    "\n",
    "\n",
    "\\###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_check_hash(left, right):\n",
    "    if left == right:\n",
    "        return -1, largest_integer\n",
    "    mid = (left + right) // 2\n",
    "    if HashCorruptedFile[left][mid] != HashOriginalFile[left][mid]:\n",
    "        min = binary_check_hash(left, mid)\n",
    "        max = binary_check_hash(mid + 1, right)\n",
    "        return min, max\n",
    "    else:\n",
    "        min1, max1 = binary_check_hash(left, mid)\n",
    "        min2, max2 = binary_check_hash(mid + 1, right)\n",
    "        return min(min1, max1), max(min1, max1)\n",
    "\n",
    "def find_min_corrupted_line(left,right):\n",
    "    if left == right:\n",
    "        return left\n",
    "    mid = (left + right) // 2\n",
    "    if HashCorruptedFile[left][mid] != HashOriginalFile[left][mid]:\n",
    "        return find_min_corrupted_line(left, mid)\n",
    "    else:\n",
    "        return find_min_corrupted_line(mid + 1, right)\n",
    "    \n",
    "\n",
    "def find_max_corrupted_line(left,right):\n",
    "    if left == right:\n",
    "        return left\n",
    "    mid = (left + right) // 2\n",
    "    if HashCorruptedFile[mid][right] != HashOriginalFile[mid][right]:\n",
    "        return find_max_corrupted_line(mid, right)\n",
    "    else:\n",
    "        return find_max_corrupted_line(left, mid-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Let $ W $ ($ W \\ll n $) be the number of corrupted lines (not necessarily consecutive). What can\n",
    "they do to find all corrupted lines by exchanging only $ O(W · \\log n) $ hash values? Describe your idea below.\n",
    "\n",
    "\\###\n",
    "\n",
    "By applying the binary check hash for $ W $ times, they can find all corrupted lines by exchanging only $ O(W · \\log n) $ hash values.\n",
    "\n",
    "\\###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Implement `binary_check_hash`.\n",
    "\n",
    "This function simulates the interactive protocol (and is the implementation of your idea in 4). It should call the function `compare` to compare two hash values, print `\"[binary_check_hash] found damaged content at line xx\"` as `naive_check_hash` does whenever a corrupted line is found, and call the function `send_words` to retrieve the original line from the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. starting computation of hash tree...\n",
      "reading files: file_corrupted1.txt file_original1.txt\n",
      "finished computation of hash tree\n",
      "\n",
      "2. starting computation of naive_check_hash()...\n",
      "[naive_check_hash] found damaged content at line 255\n",
      "[naive_check_hash] found damaged content at line 511\n",
      "[naive_check_hash] found damaged content at line 767\n",
      "[naive_check_hash] found damaged content at line 1023\n",
      "cost of navie_check_hash() = 1040 \n",
      "\n",
      "3. starting computation of binary_check_hash()...\n",
      "[binary_check_hash] found damaged content at line 255\n",
      "[binary_check_hash] found damaged content at line 511\n",
      "[binary_check_hash] found damaged content at line 767\n",
      "[binary_check_hash] found damaged content at line 1023\n",
      "cost of binary_check_hash() = 90 \n",
      "\n",
      "1. starting computation of hash tree...\n",
      "reading files: file_corrupted2.txt file_original2.txt\n",
      "finished computation of hash tree\n",
      "\n",
      "2. starting computation of naive_check_hash()...\n",
      "[naive_check_hash] found damaged content at line 255\n",
      "[naive_check_hash] found damaged content at line 511\n",
      "[naive_check_hash] found damaged content at line 767\n",
      "[naive_check_hash] found damaged content at line 1023\n",
      "[naive_check_hash] found damaged content at line 1029\n",
      "[naive_check_hash] found damaged content at line 1036\n",
      "[naive_check_hash] found damaged content at line 1279\n",
      "[naive_check_hash] found damaged content at line 1535\n",
      "[naive_check_hash] found damaged content at line 1791\n",
      "[naive_check_hash] found damaged content at line 2047\n",
      "[naive_check_hash] found damaged content at line 2303\n",
      "[naive_check_hash] found damaged content at line 2559\n",
      "[naive_check_hash] found damaged content at line 2815\n",
      "[naive_check_hash] found damaged content at line 3071\n",
      "[naive_check_hash] found damaged content at line 3327\n",
      "[naive_check_hash] found damaged content at line 3583\n",
      "[naive_check_hash] found damaged content at line 3839\n",
      "[naive_check_hash] found damaged content at line 4095\n",
      "cost of navie_check_hash() = 4168 \n",
      "\n",
      "3. starting computation of binary_check_hash()...\n",
      "[binary_check_hash] found damaged content at line 255\n",
      "[binary_check_hash] found damaged content at line 511\n",
      "[binary_check_hash] found damaged content at line 767\n",
      "[binary_check_hash] found damaged content at line 1023\n",
      "[binary_check_hash] found damaged content at line 1029\n",
      "[binary_check_hash] found damaged content at line 1036\n",
      "[binary_check_hash] found damaged content at line 1279\n",
      "[binary_check_hash] found damaged content at line 1535\n",
      "[binary_check_hash] found damaged content at line 1791\n",
      "[binary_check_hash] found damaged content at line 2047\n",
      "[binary_check_hash] found damaged content at line 2303\n",
      "[binary_check_hash] found damaged content at line 2559\n",
      "[binary_check_hash] found damaged content at line 2815\n",
      "[binary_check_hash] found damaged content at line 3071\n",
      "[binary_check_hash] found damaged content at line 3327\n",
      "[binary_check_hash] found damaged content at line 3583\n",
      "[binary_check_hash] found damaged content at line 3839\n",
      "[binary_check_hash] found damaged content at line 4095\n",
      "cost of binary_check_hash() = 396 \n",
      "\n",
      "1. starting computation of hash tree...\n",
      "reading files: file_corrupted3.txt file_original3.txt\n",
      "finished computation of hash tree\n",
      "\n",
      "2. starting computation of naive_check_hash()...\n",
      "[naive_check_hash] found damaged content at line 255\n",
      "[naive_check_hash] found damaged content at line 511\n",
      "[naive_check_hash] found damaged content at line 767\n",
      "[naive_check_hash] found damaged content at line 1023\n",
      "[naive_check_hash] found damaged content at line 1029\n",
      "[naive_check_hash] found damaged content at line 1036\n",
      "[naive_check_hash] found damaged content at line 1279\n",
      "[naive_check_hash] found damaged content at line 1535\n",
      "[naive_check_hash] found damaged content at line 1791\n",
      "[naive_check_hash] found damaged content at line 2047\n",
      "[naive_check_hash] found damaged content at line 2303\n",
      "[naive_check_hash] found damaged content at line 2559\n",
      "[naive_check_hash] found damaged content at line 2815\n",
      "[naive_check_hash] found damaged content at line 3071\n",
      "[naive_check_hash] found damaged content at line 3327\n",
      "[naive_check_hash] found damaged content at line 3583\n",
      "[naive_check_hash] found damaged content at line 3839\n",
      "[naive_check_hash] found damaged content at line 4095\n",
      "[naive_check_hash] found damaged content at line 4351\n",
      "[naive_check_hash] found damaged content at line 4607\n",
      "[naive_check_hash] found damaged content at line 4863\n",
      "[naive_check_hash] found damaged content at line 5119\n",
      "[naive_check_hash] found damaged content at line 5121\n",
      "[naive_check_hash] found damaged content at line 5140\n",
      "[naive_check_hash] found damaged content at line 5145\n",
      "[naive_check_hash] found damaged content at line 5149\n",
      "[naive_check_hash] found damaged content at line 5206\n",
      "[naive_check_hash] found damaged content at line 5217\n",
      "[naive_check_hash] found damaged content at line 5375\n",
      "[naive_check_hash] found damaged content at line 5631\n",
      "[naive_check_hash] found damaged content at line 5887\n",
      "[naive_check_hash] found damaged content at line 6143\n",
      "[naive_check_hash] found damaged content at line 6399\n",
      "[naive_check_hash] found damaged content at line 6655\n",
      "[naive_check_hash] found damaged content at line 6911\n",
      "[naive_check_hash] found damaged content at line 7167\n",
      "[naive_check_hash] found damaged content at line 7423\n",
      "[naive_check_hash] found damaged content at line 7679\n",
      "[naive_check_hash] found damaged content at line 7935\n",
      "[naive_check_hash] found damaged content at line 8191\n",
      "[naive_check_hash] found damaged content at line 8447\n",
      "[naive_check_hash] found damaged content at line 8703\n",
      "[naive_check_hash] found damaged content at line 8959\n",
      "[naive_check_hash] found damaged content at line 9215\n",
      "[naive_check_hash] found damaged content at line 9471\n",
      "[naive_check_hash] found damaged content at line 9727\n",
      "[naive_check_hash] found damaged content at line 9983\n",
      "[naive_check_hash] found damaged content at line 10239\n",
      "[naive_check_hash] found damaged content at line 10495\n",
      "[naive_check_hash] found damaged content at line 10751\n",
      "[naive_check_hash] found damaged content at line 11007\n",
      "[naive_check_hash] found damaged content at line 11263\n",
      "[naive_check_hash] found damaged content at line 11519\n",
      "[naive_check_hash] found damaged content at line 11775\n",
      "[naive_check_hash] found damaged content at line 12031\n",
      "[naive_check_hash] found damaged content at line 12287\n",
      "[naive_check_hash] found damaged content at line 12543\n",
      "[naive_check_hash] found damaged content at line 12799\n",
      "[naive_check_hash] found damaged content at line 13055\n",
      "[naive_check_hash] found damaged content at line 13311\n",
      "[naive_check_hash] found damaged content at line 13567\n",
      "[naive_check_hash] found damaged content at line 13823\n",
      "[naive_check_hash] found damaged content at line 14079\n",
      "[naive_check_hash] found damaged content at line 14335\n",
      "[naive_check_hash] found damaged content at line 14591\n",
      "[naive_check_hash] found damaged content at line 14847\n",
      "[naive_check_hash] found damaged content at line 15103\n",
      "[naive_check_hash] found damaged content at line 15359\n",
      "[naive_check_hash] found damaged content at line 15615\n",
      "[naive_check_hash] found damaged content at line 15871\n",
      "[naive_check_hash] found damaged content at line 16127\n",
      "[naive_check_hash] found damaged content at line 16383\n",
      "cost of navie_check_hash() = 16672 \n",
      "\n",
      "3. starting computation of binary_check_hash()...\n",
      "[binary_check_hash] found damaged content at line 255\n",
      "[binary_check_hash] found damaged content at line 511\n",
      "[binary_check_hash] found damaged content at line 767\n",
      "[binary_check_hash] found damaged content at line 1023\n",
      "[binary_check_hash] found damaged content at line 1029\n",
      "[binary_check_hash] found damaged content at line 1036\n",
      "[binary_check_hash] found damaged content at line 1279\n",
      "[binary_check_hash] found damaged content at line 1535\n",
      "[binary_check_hash] found damaged content at line 1791\n",
      "[binary_check_hash] found damaged content at line 2047\n",
      "[binary_check_hash] found damaged content at line 2303\n",
      "[binary_check_hash] found damaged content at line 2559\n",
      "[binary_check_hash] found damaged content at line 2815\n",
      "[binary_check_hash] found damaged content at line 3071\n",
      "[binary_check_hash] found damaged content at line 3327\n",
      "[binary_check_hash] found damaged content at line 3583\n",
      "[binary_check_hash] found damaged content at line 3839\n",
      "[binary_check_hash] found damaged content at line 4095\n",
      "[binary_check_hash] found damaged content at line 4351\n",
      "[binary_check_hash] found damaged content at line 4607\n",
      "[binary_check_hash] found damaged content at line 4863\n",
      "[binary_check_hash] found damaged content at line 5119\n",
      "[binary_check_hash] found damaged content at line 5121\n",
      "[binary_check_hash] found damaged content at line 5140\n",
      "[binary_check_hash] found damaged content at line 5145\n",
      "[binary_check_hash] found damaged content at line 5149\n",
      "[binary_check_hash] found damaged content at line 5206\n",
      "[binary_check_hash] found damaged content at line 5217\n",
      "[binary_check_hash] found damaged content at line 5375\n",
      "[binary_check_hash] found damaged content at line 5631\n",
      "[binary_check_hash] found damaged content at line 5887\n",
      "[binary_check_hash] found damaged content at line 6143\n",
      "[binary_check_hash] found damaged content at line 6399\n",
      "[binary_check_hash] found damaged content at line 6655\n",
      "[binary_check_hash] found damaged content at line 6911\n",
      "[binary_check_hash] found damaged content at line 7167\n",
      "[binary_check_hash] found damaged content at line 7423\n",
      "[binary_check_hash] found damaged content at line 7679\n",
      "[binary_check_hash] found damaged content at line 7935\n",
      "[binary_check_hash] found damaged content at line 8191\n",
      "[binary_check_hash] found damaged content at line 8447\n",
      "[binary_check_hash] found damaged content at line 8703\n",
      "[binary_check_hash] found damaged content at line 8959\n",
      "[binary_check_hash] found damaged content at line 9215\n",
      "[binary_check_hash] found damaged content at line 9471\n",
      "[binary_check_hash] found damaged content at line 9727\n",
      "[binary_check_hash] found damaged content at line 9983\n",
      "[binary_check_hash] found damaged content at line 10239\n",
      "[binary_check_hash] found damaged content at line 10495\n",
      "[binary_check_hash] found damaged content at line 10751\n",
      "[binary_check_hash] found damaged content at line 11007\n",
      "[binary_check_hash] found damaged content at line 11263\n",
      "[binary_check_hash] found damaged content at line 11519\n",
      "[binary_check_hash] found damaged content at line 11775\n",
      "[binary_check_hash] found damaged content at line 12031\n",
      "[binary_check_hash] found damaged content at line 12287\n",
      "[binary_check_hash] found damaged content at line 12543\n",
      "[binary_check_hash] found damaged content at line 12799\n",
      "[binary_check_hash] found damaged content at line 13055\n",
      "[binary_check_hash] found damaged content at line 13311\n",
      "[binary_check_hash] found damaged content at line 13567\n",
      "[binary_check_hash] found damaged content at line 13823\n",
      "[binary_check_hash] found damaged content at line 14079\n",
      "[binary_check_hash] found damaged content at line 14335\n",
      "[binary_check_hash] found damaged content at line 14591\n",
      "[binary_check_hash] found damaged content at line 14847\n",
      "[binary_check_hash] found damaged content at line 15103\n",
      "[binary_check_hash] found damaged content at line 15359\n",
      "[binary_check_hash] found damaged content at line 15615\n",
      "[binary_check_hash] found damaged content at line 15871\n",
      "[binary_check_hash] found damaged content at line 16127\n",
      "[binary_check_hash] found damaged content at line 16383\n",
      "cost of binary_check_hash() = 1584 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hash Values for words in New File\n",
    "# HashCorruptedFile[i,j] = Hash value of lines i to j in Corrupted File\n",
    "HashCorruptedFile = []\n",
    "\n",
    "# Hash Values for words in Old File\n",
    "# HashOriginalFile[i,j] = Hash value of lines i to j in Original File\n",
    "HashOriginalFile = []\n",
    "\n",
    "# Words in the Corrupted and Original File\n",
    "wordsCorrupted = []\n",
    "wordsOriginal = []\n",
    "\n",
    "# n : number of lines in each file\n",
    "n = 1 # default value\n",
    "\n",
    "# variable to measure network transmission cost\n",
    "cost = 0\n",
    "\n",
    "# penalty value for transmitting the whole line\n",
    "penalty = 4\n",
    "\n",
    "\n",
    "# feel free to add additional functions\n",
    "\n",
    "def hash_function(s):\n",
    "    '''\n",
    "    compute and return the hash value of the string s.\n",
    "\n",
    "    You can use built-in hash() (or any other method) to calculate a hash code. But you should finally return a division hash code (something % something). \n",
    "    '''\n",
    "    #######################\n",
    "    #                     #\n",
    "    #      Question 1     #\n",
    "    #     TO IMPLEMENT    #\n",
    "    #                     #\n",
    "    #######################\n",
    "    return hash(s) % 10007\n",
    "\n",
    "\n",
    "def compute_node_values():\n",
    "    ''' \n",
    "    in the first part of compute_hash_tree(), we computed HashOriginalFile[0][0], HashOriginalFile[1][1], HashOriginalFile[2][2].... etc\n",
    "    \n",
    "    Now, here in compute_node_values(), you have to calculate HashOriginalFile[i][j] where i < j\n",
    "    So, HashOriginalFile[2][4] = hash_function(\"line 2-4 of corrupted file\"). It depends on your own design. \n",
    "    \n",
    "    For example, HashOriginalFile[2][4] can be = hash_function(hash_function(line 2) + 2*hash_function(line 3) + 3*hash_function(line 4)).... but it is good? Perhaps not. So, write your own hash function here! \n",
    "    '''\n",
    "    compute_node_value(HashCorruptedFile, 0, n - 1)\n",
    "    compute_node_value(HashOriginalFile, 0, n - 1)\n",
    "\n",
    "def compute_node_value(table, i, j):\n",
    "    '''\n",
    "    it calculates table[i][j], where table could be HashCorruptedFile or HashOriginalFile.\n",
    "\n",
    "    Remember you are doing a binary search here. It's not necessary to try out all combination of i, j. You only need to consider (0, n), (0, n/2), (n/2, n), ... \n",
    "    '''\n",
    "    #######################\n",
    "    #                     #\n",
    "    #      Question 2     #\n",
    "    #     TO IMPLEMENT    #\n",
    "    #                     #\n",
    "    #######################\n",
    "    if i == j:\n",
    "        return\n",
    "    mid = (i + j) // 2\n",
    "    compute_node_value(table, i, mid)\n",
    "    compute_node_value(table, mid + 1, j)\n",
    "    table[i][j] = hash_function(table[i][mid] + table[mid + 1][j])\n",
    "\n",
    "\n",
    "\n",
    "def binary_check_hash(left, right):\n",
    "    ''' \n",
    "    performs binary search over the hash tree.\n",
    "\n",
    "    Search through the whole tree. \n",
    "    The output should be similar to naive_check_hash().\n",
    "    '''\n",
    "    global cost, penalty\n",
    "    #######################\n",
    "    #                     #\n",
    "    #      Question 5     #\n",
    "    #     TO IMPLEMENT    #\n",
    "    #                     #\n",
    "    #######################\n",
    "    if left == right:\n",
    "        if not compare(HashCorruptedFile[left][left], HashOriginalFile[left][left]):\n",
    "            print(\"[binary_check_hash] found damaged content at line\", left)\n",
    "            send_word()\n",
    "    else:\n",
    "        mid = (left + right) // 2\n",
    "        if not compare(HashCorruptedFile[left][mid], HashOriginalFile[left][mid]):\n",
    "            binary_check_hash(left, mid)\n",
    "        if not compare(HashCorruptedFile[mid + 1][right], HashOriginalFile[mid + 1][right]):\n",
    "            binary_check_hash(mid + 1, right)\n",
    "\n",
    "\n",
    "# read fileCorrupted and fileOriginal, save to wordsCorrupted and wordsOriginal\n",
    "def read_files(fileCorrupted, fileOriginal):\n",
    "    print(\"reading files:\", fileCorrupted, fileOriginal)\n",
    "    with open(fileCorrupted, 'r') as fCorrupted:\n",
    "        for line in fCorrupted:\n",
    "            wordsCorrupted.append(line.rstrip())\n",
    "    with open(fileOriginal, 'r') as fOriginal:\n",
    "        for line in fOriginal:\n",
    "            wordsOriginal.append(line.rstrip())\n",
    "\n",
    "\n",
    "# Compute the hash values of the leaf nodes in the Hash Tree\n",
    "def compute_hash_tree():\n",
    "    for i in range(n):\n",
    "        HashCorruptedFile.append([])\n",
    "        HashOriginalFile.append([])\n",
    "        for _ in range(n):\n",
    "            HashCorruptedFile[i].append(None)\n",
    "            HashOriginalFile[i].append(None)\n",
    "\n",
    "    for i in range(n):\n",
    "        HashCorruptedFile[i][i] = hash_function(wordsCorrupted[i])\n",
    "        HashOriginalFile[i][i] = hash_function(wordsOriginal[i])\n",
    "\n",
    "    compute_node_values()\n",
    "\n",
    "\n",
    "# compares the two hash values. total cost increase by 1\n",
    "def compare(oldhash, newhash):\n",
    "    global cost\n",
    "    cost += 1\n",
    "    return oldhash == newhash\n",
    "\n",
    "\n",
    "# adds the penalty of sending the whole line over network transmission\n",
    "def send_word():\n",
    "    global cost, penalty\n",
    "    cost += penalty\n",
    "\n",
    "# naive hash check method, goes over all the lines and compares them.\n",
    "def naive_check_hash(left, right):\n",
    "    global cost, penalty\n",
    "    for i in range(left, right + 1):\n",
    "        if not compare(HashCorruptedFile[i][i], HashOriginalFile[i][i]):\n",
    "            print(\"[naive_check_hash] found damaged content at line\", i)\n",
    "            send_word()\n",
    "\n",
    "\n",
    "# performs the naive_check_hash algorithm and binary_check_hash algorithm.\n",
    "# compares filename1 and filename2 with n lines each\n",
    "# print out the cost\n",
    "def file_transfer(filename1, filename2, n1):\n",
    "    global cost, n\n",
    "    n = n1\n",
    "\n",
    "    print(\"1. starting computation of hash tree...\")\n",
    "    read_files(filename1, filename2)\n",
    "    compute_hash_tree()\n",
    "    print(\"finished computation of hash tree\\n\")\n",
    "\n",
    "    print(\"2. starting computation of naive_check_hash()...\")\n",
    "    cost = 0\n",
    "    naive_check_hash(0, n - 1)\n",
    "    print(\"cost of navie_check_hash() =\", cost, \"\\n\")\n",
    "\n",
    "    print(\"3. starting computation of binary_check_hash()...\")\n",
    "    cost = 0\n",
    "    binary_check_hash(0, n - 1)\n",
    "    print(\"cost of binary_check_hash() =\", cost, \"\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_transfer(\"file_corrupted1.txt\", \"file_original1.txt\", 1024)\n",
    "    file_transfer(\"file_corrupted2.txt\", \"file_original2.txt\", 4096)\n",
    "    file_transfer(\"file_corrupted3.txt\", \"file_original3.txt\", 16384)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90244c378c7e3257c2f5a89cc828b05c1d67956a5c0682215f78ff63c5f4d2c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'> CSC4120 Programming Assignment 1 </h1>\n",
    "\n",
    "## Submission Requirements\n",
    "\n",
    "   The submission <font color = #FF0000>deadline is January 28 (Sun.), 2024, 11:59 pm</font>. Solutions submitted after the deadline will be graded as 0 points. Please submit an **ipynb** file and clearly state your group members' student IDs. Otherwise, your points will be deducted.\n",
    "\n",
    "## What you need to do\n",
    "\n",
    "1. Understand the document distance problem.\n",
    "\n",
    "2. Understand the python code and how we improve the algorithm in each step.\n",
    "\n",
    "3. Implement merge sort and the dictionary version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student IDs\n",
    "\n",
    "- 120090244\n",
    "- 121090271\n",
    "- 122090031"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "import cProfile\n",
    "import string\n",
    "\n",
    "filename_1 = \"file1.txt\"\n",
    "filename_2 = \"file2.txt\"\n",
    "translation_table = str.maketrans(string.punctuation + string.ascii_uppercase,\n",
    "                                     \" \"*len(string.punctuation) + string.ascii_lowercase)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial version of document distance\n",
    "\n",
    "This program computes the \"distance\" between two text files as the angle between their word frequency vectors (in radians).\n",
    "\n",
    "For each input file, a word-frequency vector is computed as follows:\n",
    "\n",
    "   (1) the specified file is read in\n",
    "\n",
    "   (2) it is converted into a list of alphanumeric \"words\"\n",
    "\n",
    "       Here a \"word\" is a sequence of consecutive alphanumeric\n",
    "       characters.  Non-alphanumeric characters are treated as blanks.\n",
    "       Case is not significant.\n",
    "\n",
    "   (3) for each word, its frequency of occurrence is determined\n",
    "\n",
    "The \"distance\" between two vectors is the angle between them.\n",
    "\n",
    "If $ x = (x_1, x_2, ..., x_n) $ is the first vector ($ x_i $ = freq of word i)\n",
    "and $ y = (y_1, y_2, ..., y_n) $ is the second vector,\n",
    "then the angle between them is defined as:\n",
    "\n",
    "   $$ d(x,y) = \\arccos{\\left(\\frac{\\operatorname*{innerProduct}(x,y)}{\\operatorname*{norm}(x) * \\operatorname{norm}(y)}\\right)} $$\n",
    "\n",
    "where:\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\operatorname*{innerProduct}(x,y) = x_1*y_1 + x_2*y_2 + \\cdots + x_n*y_n \\\\[1em]\n",
    "\\operatorname*{norm}(x) = \\sqrt{\\operatorname*{innerProduct}(x,x)}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "   ***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What you need to do\n",
    "\n",
    "Run the code and report the running time.\n",
    "\n",
    "There are 71158 function calls (71147 primitive calls) in 1.880 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance between the documents is: 0.619328 (radians)\n",
      "         71158 function calls (71147 primitive calls) in 1.880 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        2    0.000    0.000    0.004    0.002 573875801.py:1(read_file)\n",
      "        2    1.686    0.843    1.716    0.858 573875801.py:13(get_words_from_line_list)\n",
      "    23110    0.004    0.000    0.029    0.000 573875801.py:24(get_words_from_string)\n",
      "        2    0.146    0.073    0.146    0.073 573875801.py:37(count_frequency)\n",
      "        2    0.000    0.000    1.866    0.933 573875801.py:51(word_frequencies_for_file)\n",
      "        3    0.011    0.004    0.011    0.004 573875801.py:61(inner_product)\n",
      "        1    0.000    0.000    0.011    0.011 573875801.py:76(vector_angle)\n",
      "        1    0.001    0.001    1.879    1.879 573875801.py:86(docdist1)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen abc>:121(__subclasscheck__)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen codecs>:260(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen codecs>:309(__init__)\n",
      "       84    0.000    0.000    0.000    0.000 <frozen codecs>:319(decode)\n",
      "        5    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1390(_handle_fromlist)\n",
      "        1    0.000    0.000    1.879    1.879 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 _base.py:337(_invoke_callbacks)\n",
      "        1    0.000    0.000    0.000    0.000 _base.py:537(set_result)\n",
      "        1    0.000    0.000    0.001    0.001 asyncio.py:200(_handle_events)\n",
      "        1    0.000    0.000    0.000    0.000 asyncio.py:225(add_callback)\n",
      "        5    0.000    0.000    0.000    0.000 attrsettr.py:42(__getattr__)\n",
      "        5    0.000    0.000    0.000    0.000 attrsettr.py:65(_get_attr_opt)\n",
      "        1    0.000    0.000    0.000    0.000 base_events.py:1879(_add_callback)\n",
      "        3    0.000    0.000    0.001    0.000 base_events.py:1894(_run_once)\n",
      "        5    0.000    0.000    0.000    0.000 base_events.py:1989(get_debug)\n",
      "        3    0.000    0.000    0.000    0.000 base_events.py:537(_check_closed)\n",
      "        1    0.000    0.000    0.000    0.000 base_events.py:717(is_closed)\n",
      "        4    0.000    0.000    0.000    0.000 base_events.py:731(time)\n",
      "        2    0.000    0.000    0.000    0.000 base_events.py:782(call_soon)\n",
      "        3    0.000    0.000    0.000    0.000 base_events.py:811(_call_soon)\n",
      "        1    0.000    0.000    0.000    0.000 base_events.py:835(call_soon_threadsafe)\n",
      "        1    0.000    0.000    0.000    0.000 concurrent.py:181(future_set_result_unless_cancelled)\n",
      "        1    0.000    0.000    0.000    0.000 decorator.py:199(fix)\n",
      "        1    0.000    0.000    0.002    0.002 decorator.py:229(fun)\n",
      "       29    0.000    0.000    0.000    0.000 enum.py:1116(__new__)\n",
      "       15    0.000    0.000    0.000    0.000 enum.py:1531(__or__)\n",
      "        7    0.000    0.000    0.000    0.000 enum.py:1541(__and__)\n",
      "       29    0.000    0.000    0.000    0.000 enum.py:713(__call__)\n",
      "        3    0.000    0.000    0.000    0.000 events.py:32(__init__)\n",
      "      5/3    0.000    0.000    0.000    0.000 events.py:82(_run)\n",
      "        1    0.000    0.000    0.000    0.000 futures.py:394(_call_set_state)\n",
      "        1    0.000    0.000    0.002    0.002 history.py:54(only_when_enabled)\n",
      "        1    0.000    0.000    0.001    0.001 history.py:824(_writeout_input_cache)\n",
      "        1    0.000    0.000    0.000    0.000 history.py:830(_writeout_output_cache)\n",
      "        1    0.000    0.000    0.001    0.001 history.py:836(writeout_cache)\n",
      "        4    0.000    0.000    0.000    0.000 inspect.py:2782(name)\n",
      "       10    0.000    0.000    0.000    0.000 inspect.py:2794(kind)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2874(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2882(args)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2905(kwargs)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2935(apply_defaults)\n",
      "        4    0.000    0.000    0.000    0.000 inspect.py:3075(parameters)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:3119(_bind)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:3254(bind)\n",
      "        2    0.000    0.000    0.000    0.000 interactiveshell.py:301(_modified_open)\n",
      "        1    0.000    0.000    0.000    0.000 ioloop.py:742(_run_callback)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:138(_event_pipe)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:157(_handle_event)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:213(_is_master_process)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:216(_check_mp_mode)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:255(closed)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:259(schedule)\n",
      "        2    0.000    0.000    0.001    0.000 iostream.py:276(<lambda>)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:278(_really_send)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:505(parent_header)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:550(_is_master_process)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:577(_schedule_flush)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:655(write)\n",
      "        2    0.000    0.000    0.000    0.000 ipkernel.py:770(_clean_thread_parent_frames)\n",
      "        1    0.000    0.000    0.000    0.000 kernelbase.py:302(poll_control_queue)\n",
      "        1    0.000    0.000    0.000    0.000 locks.py:224(clear)\n",
      "        3    0.000    0.000    0.000    0.000 queue.py:209(_qsize)\n",
      "        3    0.000    0.000    0.000    0.000 queue.py:97(empty)\n",
      "        1    0.000    0.000    0.000    0.000 queues.py:173(qsize)\n",
      "        1    0.000    0.000    0.000    0.000 queues.py:177(empty)\n",
      "        1    0.000    0.000    0.000    0.000 queues.py:186(put)\n",
      "        1    0.000    0.000    0.000    0.000 queues.py:209(put_nowait)\n",
      "        1    0.000    0.000    0.000    0.000 queues.py:225(get)\n",
      "        1    0.000    0.000    0.000    0.000 queues.py:256(get_nowait)\n",
      "        1    0.000    0.000    0.000    0.000 queues.py:309(_get)\n",
      "        1    0.000    0.000    0.000    0.000 queues.py:312(_put)\n",
      "        1    0.000    0.000    0.000    0.000 queues.py:317(__put_internal)\n",
      "        2    0.000    0.000    0.000    0.000 queues.py:322(_consume_expired)\n",
      "        1    0.000    0.000    0.000    0.000 queues.py:59(_set_timeout)\n",
      "        1    0.000    0.000    0.000    0.000 selector_events.py:129(_read_from_self)\n",
      "        1    0.000    0.000    0.000    0.000 selector_events.py:141(_write_to_self)\n",
      "        3    0.000    0.000    0.000    0.000 selector_events.py:746(_process_events)\n",
      "        1    0.000    0.000    0.000    0.000 selectors.py:275(_key_from_fd)\n",
      "      2/1    0.000    0.000    0.000    0.000 selectors.py:558(select)\n",
      "       15    0.000    0.000    0.000    0.000 socket.py:621(send)\n",
      "        2    0.000    0.000    0.000    0.000 socket.py:698(send_multipart)\n",
      "        2    0.000    0.000    0.000    0.000 socket.py:777(recv_multipart)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1153(_wait_for_tstate_lock)\n",
      "        7    0.000    0.000    0.000    0.000 threading.py:1196(ident)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1220(is_alive)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1534(enumerate)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:299(__enter__)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:302(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:308(_release_save)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:311(_acquire_restore)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:314(_is_owned)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:394(notify)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:424(notify_all)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:601(is_set)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:627(clear)\n",
      "        1    0.000    0.000    0.000    0.000 traitlets.py:1512(_notify_trait)\n",
      "        1    0.000    0.000    0.000    0.000 traitlets.py:1523(notify_change)\n",
      "        1    0.000    0.000    0.000    0.000 traitlets.py:1527(_notify_observers)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:2304(validate)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:3474(validate)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:3486(validate_elements)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:3624(validate_elements)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:3631(set)\n",
      "        6    0.000    0.000    0.000    0.000 traitlets.py:629(get)\n",
      "        6    0.000    0.000    0.000    0.000 traitlets.py:676(__get__)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:689(set)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:708(__set__)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:718(_validate)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:727(_cross_validate)\n",
      "        2    0.000    0.000    0.000    0.000 typing.py:1175(__instancecheck__)\n",
      "        4    0.000    0.000    0.000    0.000 typing.py:1239(__hash__)\n",
      "        2    0.000    0.000    0.000    0.000 typing.py:1446(__subclasscheck__)\n",
      "       24    0.000    0.000    0.000    0.000 typing.py:2119(cast)\n",
      "        6    0.000    0.000    0.000    0.000 typing.py:378(inner)\n",
      "        1    0.000    0.000    0.000    0.000 tz.py:74(utcoffset)\n",
      "        1    0.000    0.000    0.000    0.000 unix_events.py:81(_process_self_data)\n",
      "        5    0.000    0.000    0.000    0.000 zmqstream.py:562(receiving)\n",
      "        3    0.000    0.000    0.000    0.000 zmqstream.py:566(sending)\n",
      "        2    0.000    0.000    0.001    0.000 zmqstream.py:580(_run_callback)\n",
      "        2    0.000    0.000    0.001    0.000 zmqstream.py:607(_handle_events)\n",
      "        2    0.000    0.000    0.001    0.000 zmqstream.py:648(_handle_recv)\n",
      "        3    0.000    0.000    0.000    0.000 zmqstream.py:687(_rebuild_io_state)\n",
      "        3    0.000    0.000    0.000    0.000 zmqstream.py:710(_update_handler)\n",
      "        1    0.000    0.000    0.000    0.000 zmqstream.py:718(<lambda>)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _abc._abc_subclasscheck}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _asyncio.get_running_loop}\n",
      "       84    0.000    0.000    0.000    0.000 {built-in method _codecs.utf_8_decode}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _contextvars.copy_context}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _io.open}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
      "    81/77    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "       18    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method math.acos}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method math.sqrt}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method time.monotonic}\n",
      "        1    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.RLock' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        7    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "        2    0.001    0.000    0.001    0.000 {method '__exit__' of 'sqlite3.Connection' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method '_is_owned' of '_thread.RLock' objects}\n",
      "      4/3    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "     1052    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'cancelled' of '_asyncio.Future' objects}\n",
      "      2/1    0.000    0.000    0.000    0.000 {method 'control' of 'select.kqueue' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'done' of '_asyncio.Future' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'execute' of 'sqlite3.Connection' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'get' of '_contextvars.ContextVar' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'items' of 'mappingproxy' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'popleft' of 'collections.deque' objects}\n",
      "        2    0.004    0.002    0.004    0.002 {method 'readlines' of '_io._IOBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'recv' of '_socket.socket' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}\n",
      "      4/2    0.000    0.000    0.001    0.000 {method 'run' of '_contextvars.Context' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'send' of '_socket.socket' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'set_result' of '_asyncio.Future' objects}\n",
      "    23110    0.005    0.000    0.005    0.000 {method 'split' of 'str' objects}\n",
      "    23110    0.021    0.000    0.021    0.000 {method 'translate' of 'str' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'values' of 'mappingproxy' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_file(filename):\n",
    "    \"\"\" \n",
    "    Read the text file with the given filename;\n",
    "    return a list of the lines of text in the file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        f = open(filename, 'r', encoding= 'utf-8')\n",
    "        return f.readlines()\n",
    "    except IOError:\n",
    "        print(\"Error opening or reading input file: \", filename)\n",
    "        sys.exit()\n",
    "\n",
    "def get_words_from_line_list(L):\n",
    "    \"\"\"\n",
    "    Parse the given list L of text lines into words.\n",
    "    Return list of all words found.\n",
    "    \"\"\"\n",
    "    word_list = []\n",
    "    for line in L:\n",
    "        words_in_line = get_words_from_string(line)\n",
    "        word_list = word_list + words_in_line\n",
    "    return word_list\n",
    "\n",
    "def get_words_from_string(line):\n",
    "    \"\"\"\n",
    "    Return a list of the words in the given input string,\n",
    "    converting each word to lower-case.\n",
    "\n",
    "    Input:  line (a string)\n",
    "    Output: a list of strings \n",
    "              (each string is a sequence of alphanumeric characters)\n",
    "    \"\"\"\n",
    "    line = line.translate(translation_table)\n",
    "    word_list = line.split()\n",
    "    return word_list\n",
    "\n",
    "def count_frequency(word_list):\n",
    "    \"\"\"\n",
    "    Return a list giving pairs of form: (word,frequency)\n",
    "    \"\"\"\n",
    "    L = []\n",
    "    for new_word in word_list:\n",
    "        for entry in L:\n",
    "            if new_word == entry[0]:\n",
    "                entry[1] = entry[1] + 1\n",
    "                break\n",
    "        else:\n",
    "            L.append([new_word, 1])\n",
    "    return L\n",
    "\n",
    "def word_frequencies_for_file(filename):\n",
    "    \"\"\"\n",
    "    Return alphabetically sorted list of (word,frequency) pairs \n",
    "    for the given file.\n",
    "    \"\"\"\n",
    "    line_list = read_file(filename)\n",
    "    word_list = get_words_from_line_list(line_list)\n",
    "    freq_mapping = count_frequency(word_list)\n",
    "    return freq_mapping\n",
    "\n",
    "def inner_product(L1, L2):\n",
    "    \"\"\"\n",
    "    Inner product between two vectors, where vectors\n",
    "    are represented as lists of (word,freq) pairs.\n",
    "\n",
    "    Example: inner_product([[\"and\",3],[\"of\",2],[\"the\",5]],\n",
    "                           [[\"and\",4],[\"in\",1],[\"of\",1],[\"this\",2]]) = 14.0 \n",
    "    \"\"\"\n",
    "    sum = 0.0\n",
    "    for word1, count1 in L1:\n",
    "        for word2, count2 in L2:\n",
    "            if word1 == word2:\n",
    "                sum += count1 * count2\n",
    "    return sum\n",
    "\n",
    "def vector_angle(L1, L2):\n",
    "    \"\"\"\n",
    "    The input is a list of (word,freq) pairs, sorted alphabetically.\n",
    "\n",
    "    Return the angle between these two vectors.\n",
    "    \"\"\"\n",
    "    numerator = inner_product(L1, L2)\n",
    "    denominator = math.sqrt(inner_product(L1, L1) * inner_product(L2, L2))\n",
    "    return math.acos(numerator / denominator)\n",
    "\n",
    "def docdist1():\n",
    "    document_vector_1 = word_frequencies_for_file(filename_1)\n",
    "    document_vector_2 = word_frequencies_for_file(filename_2)\n",
    "    distance = vector_angle(document_vector_1, document_vector_2)\n",
    "    print(\"The distance between the documents is: %0.6f (radians)\"%distance)\n",
    "\n",
    "cProfile.run(\"docdist1()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Change concatenate to extend in get_words_from_line_list\n",
    "\n",
    "Compare the running time, analyze why we get improvement (or why not), identify it using `cProfile`.\n",
    "\n",
    "\\###\n",
    "\n",
    "Your answer goes here\n",
    "\n",
    "\\###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_from_line_list(L):\n",
    "    \"\"\"\n",
    "    Parse the given list L of text lines into words.\n",
    "    Return list of all words found.\n",
    "    \"\"\"\n",
    "    word_list = []\n",
    "    for line in L:\n",
    "        words_in_line = get_words_from_string(line)\n",
    "        word_list.extend(words_in_line)\n",
    "    return word_list\n",
    "\n",
    "def docdist2():\n",
    "    document_vector_1 = word_frequencies_for_file(filename_1)\n",
    "    document_vector_2 = word_frequencies_for_file(filename_2)\n",
    "    distance = vector_angle(document_vector_1, document_vector_2)\n",
    "    print(\"The distance between the documents is: %0.6f (radians)\"%distance)\n",
    "\n",
    "cProfile.run(\"docdist2()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sort the document vector\n",
    "\n",
    "Compare the running time, analyze why we get improvement (or why not), identify it using `cProfile`.\n",
    "\n",
    "\\###\n",
    "\n",
    "Your answer goes here\n",
    "\n",
    "\\###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertion_sort(A):\n",
    "    \"\"\"\n",
    "    Sort list A into order, in place.\n",
    "\n",
    "    From Cormen/Leiserson/Rivest/Stein,\n",
    "    Introduction to Algorithms (second edition), page 17,\n",
    "    modified to adjust for fact that Python arrays use \n",
    "    0-indexing.\n",
    "    \"\"\"\n",
    "    for j in range(len(A)):\n",
    "        key = A[j]\n",
    "        # insert A[j] into sorted sequence A[0..j-1]\n",
    "        i = j - 1\n",
    "        while i > -1 and A[i] > key:\n",
    "            A[i + 1] = A[i]\n",
    "            i = i - 1\n",
    "        A[i + 1] = key\n",
    "    return A\n",
    "    \n",
    "def word_frequencies_for_file(filename):\n",
    "    \"\"\"\n",
    "    Return alphabetically sorted list of (word,frequency) pairs \n",
    "    for the given file.\n",
    "    \"\"\"\n",
    "    line_list = read_file(filename)\n",
    "    word_list = get_words_from_line_list(line_list)\n",
    "    freq_mapping = count_frequency(word_list)\n",
    "    insertion_sort(freq_mapping)\n",
    "    return freq_mapping\n",
    "\n",
    "def inner_product(L1, L2):\n",
    "    \"\"\"\n",
    "    Inner product between two vectors, where vectors\n",
    "    are represented as alphabetically sorted (word,freq) pairs.\n",
    "\n",
    "    Example: inner_product([[\"and\",3],[\"of\",2],[\"the\",5]],\n",
    "                           [[\"and\",4],[\"in\",1],[\"of\",1],[\"this\",2]]) = 14.0 \n",
    "    \"\"\"\n",
    "    sum = 0.0\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i < len(L1) and j < len(L2):\n",
    "        # L1[i:] and L2[j:] yet to be processed\n",
    "        if L1[i][0] == L2[j][0]:\n",
    "            # both vectors have this word\n",
    "            sum += L1[i][1] * L2[j][1]\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif L1[i][0] < L2[j][0]:\n",
    "            # word L1[i][0] is in L1 but not L2\n",
    "            i += 1\n",
    "        else:\n",
    "            # word L2[j][0] is in L2 but not L1\n",
    "            j += 1\n",
    "    return sum\n",
    "\n",
    "def docdist3():\n",
    "    sorted_word_list_1 = word_frequencies_for_file(filename_1)\n",
    "    sorted_word_list_2 = word_frequencies_for_file(filename_2)\n",
    "    distance = vector_angle(sorted_word_list_1, sorted_word_list_2)\n",
    "    print(\"The distance between the documents is: %0.6f (radians)\"%distance)\n",
    "\n",
    "cProfile.run(\"docdist3()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Change sorting from insertion sort to merge sort\n",
    "\n",
    "Implement merge sort.\n",
    "\n",
    "Compare the running time, analyze why we get improvement (or why not), identify it using `cProfile`.\n",
    "\n",
    "\\###\n",
    "\n",
    "Your answer goes here\n",
    "\n",
    "\\###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sort(A):\n",
    "    \"\"\"\n",
    "    Sort list A into order, and return result.\n",
    "    \"\"\"\n",
    "    #######################\n",
    "    #                     #\n",
    "    #     TO IMPLEMENT    #\n",
    "    #                     #\n",
    "    #######################\n",
    "\n",
    "def word_frequencies_for_file(filename):\n",
    "    \"\"\"\n",
    "    Return alphabetically sorted list of (word,frequency) pairs \n",
    "    for the given file.\n",
    "    \"\"\"\n",
    "    line_list = read_file(filename)\n",
    "    word_list = get_words_from_line_list(line_list)\n",
    "    freq_mapping = count_frequency(word_list)\n",
    "    freq_mapping = merge_sort(freq_mapping)\n",
    "    return freq_mapping\n",
    "\n",
    "def docdist3():\n",
    "    sorted_word_list_1 = word_frequencies_for_file(filename_1)\n",
    "    sorted_word_list_2 = word_frequencies_for_file(filename_2)\n",
    "    distance = vector_angle(sorted_word_list_1, sorted_word_list_2)\n",
    "    print(\"The distance between the documents is: %0.6f (radians)\"%distance)\n",
    "\n",
    "cProfile.run(\"docdist3()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Use dictionaries instead of lists\n",
    "\n",
    "Implement the algorithm using dictionaries instead of lists. \n",
    "\n",
    "Analyze why we get improvement and identify it using `cProfile`.\n",
    "\n",
    "\\### \n",
    "\n",
    "Your answer goes here\n",
    "\n",
    "\\###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    \"\"\" \n",
    "    Read the text file with the given filename;\n",
    "    return a list of the lines of text in the file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        f = open(filename, 'r', encoding= 'utf-8')\n",
    "        return f.readlines()\n",
    "    except IOError:\n",
    "        print(\"Error opening or reading input file: \", filename)\n",
    "        sys.exit()\n",
    "\n",
    "def get_words_from_line_list(L):\n",
    "    \"\"\"\n",
    "    Parse the given list L of text lines into words.\n",
    "    Return list of all words found.\n",
    "    \"\"\"\n",
    "    word_list = []\n",
    "    for line in L:\n",
    "        words_in_line = get_words_from_string(line)\n",
    "        word_list.extend(words_in_line)\n",
    "    return word_list\n",
    "\n",
    "def get_words_from_string(line):\n",
    "    \"\"\"\n",
    "    Return a list of the words in the given input string,\n",
    "    converting each word to lower-case.\n",
    "\n",
    "    Input:  line (a string)\n",
    "    Output: a list of strings \n",
    "              (each string is a sequence of alphanumeric characters)\n",
    "    \"\"\"\n",
    "    line = line.translate(translation_table)\n",
    "    word_list = line.split()\n",
    "    return word_list\n",
    "\n",
    "def count_frequency(word_list):\n",
    "    \"\"\"\n",
    "    Input a list of words\n",
    "    Return a DICTIONARY of (word, frequency) pairs\n",
    "    \"\"\"\n",
    "    #######################\n",
    "    #                     #\n",
    "    #     TO IMPLEMENT    #\n",
    "    #                     #\n",
    "    #######################\n",
    "\n",
    "def word_frequencies_for_file(filename):\n",
    "    \"\"\"\n",
    "    Return dictionary of (word,frequency) pairs for the given file.\n",
    "    \"\"\"\n",
    "\n",
    "    line_list = read_file(filename)\n",
    "    word_list = get_words_from_line_list(line_list)\n",
    "    freq_mapping = count_frequency(word_list)\n",
    "    return freq_mapping\n",
    "\n",
    "def inner_product(D1, D2):\n",
    "    \"\"\"\n",
    "    Inner product between two vectors, where vectors\n",
    "    are represented as dictionaries of (word,freq) pairs.\n",
    "\n",
    "    Example: inner_product({\"and\":3,\"of\":2,\"the\":5},\n",
    "                           {\"and\":4,\"in\":1,\"of\":1,\"this\":2}) = 14.0 \n",
    "    \"\"\"\n",
    "    #######################\n",
    "    #                     #\n",
    "    #     TO IMPLEMENT    #\n",
    "    #                     #\n",
    "    #######################\n",
    "\n",
    "def vector_angle(D1, D2):\n",
    "    \"\"\"\n",
    "    The input are two vectors represented as dictionary of (word,freq) pairs.\n",
    "    Return the angle between these two vectors.\n",
    "    \"\"\"\n",
    "    numerator = inner_product(D1, D2)\n",
    "    denominator = math.sqrt(inner_product(D1, D1) * inner_product(D2, D2))\n",
    "    return math.acos(numerator / denominator)\n",
    "\n",
    "def docdist5():\n",
    "    word_dict_1 = word_frequencies_for_file(filename_1)\n",
    "    word_dict_2 = word_frequencies_for_file(filename_2)\n",
    "    distance = vector_angle(word_dict_1, word_dict_2)\n",
    "    print(\"The distance between the documents is: %0.6f (radians)\"%distance)\n",
    "\n",
    "cProfile.run(\"docdist5()\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "7b2d0d3375fa4c09a79b62c1c2a6607fb9977a0272e3dcc1e342ecd43aadb5b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
